Data Engineering Project on COVID-19 DataLake by using SQL

This repository hosts SQL code dedicated to exploring COVID-19 data. It demonstrates various SQL techniques for gaining insights and conducting analysis on COVID-19 data. The code in this repository effectively leverages SQL techniques such as joins, CTEs (Common Table Expressions), temporary tables, window functions, aggregate functions, creating views, and data type conversions to provide comprehensive insights into COVID-19 cases, deaths, and vaccination data. I analyzed this data on Google Cloud SQL; data importing was so much easier than any other import-export wizard.

Data Engineering Project on COVID-19 DataLake by AWS

Performing data modeling, data wrangling and extract-load-transform using python on the COVID-19 Data Lake available on registry of open data AWS using various AWS tools such as boto3, Glue, S3, Athena and Redshift.

Tools and Usages:

Amazon S3 - Storing the data
Crawler - Used to extract all the schema and information straight from S3
Amazon Athena - Running adhoc sql queries on the available data in S3
AWS Glue - data transformation
Amazon Redshift - storing the tranfromed dimensional model in datawarehouse
boto3 - aws python sdk for create, configure, and manage AWS services.
